.# R-回归
一般线性回归  lm(y~x1+x2+...+xk,data=  )
    ~ 分隔符号，左边为响应变量，右边为解释变量。例如，要通过x、z和w预测y，代码为y ~ x + z + w
    + 分隔预测变量
    : 表示预测变量的交互项。例如，要通过x、z及x与z的交互项预测y，代码为y ~ x + z + x:z
    * 表示所有可能交互项的简洁方式。代码y~ x * z * w可展开为y ~ x + z + w + x:z + x:w + z:w + x:z:w
    ^ 表示交互项达到某个次数。代码y ~ (x + z + w)^2可展开为y ~ x + z + w + x:z + x:w + z:w
    . 表示包含除因变量外的所有变量。例如，若一个数据框包含变量x、y、z和w，代码y ~ .可展开为y ~ x +z + w
    - 减号，表示从等式中移除某个变量。例如，y ~ (x + z + w)^2 – x:w可展开为y ~ x + z + w +x:z + z:w
    -1 删除截距项。例如，表达式y ~ x - 1拟合y在x上的回归，并强制直线通过原点
    I() 从算术的角度来解释括号中的元素。例如，y ~ x + (z + w)^2将展开为y ~ x + z + w + z:w。相反, 代码y
               ~ x + I((z + w)^2)将展开为y ~ x + h, h是一个由z和w的平方和创建的新变量
    function 可以在表达式中用的数学函数。例如，log(y) ~ x + z + w表示通过x、z和w来预测log(y)
summary() 展示拟合模型的详细结果
coefficients() 列出拟合模型的模型参数（截距项和斜率）
confint() 提供模型参数的置信区间（默认95%）
fitted() 列出拟合模型的预测值
residuals() 列出拟合模型的残差值
anova() 生成一个拟合模型的方差分析表，或者比较两个或更多拟合模型的方差分析表
vcov() 列出模型参数的协方差矩阵
AIC() 输出赤池信息统计量
plot() 生成评价拟合模型的诊断图
predict() 用拟合模型对新的数据集预测响应变量值

多元线性回归
library(car) 中scatterplotMatrix()函数则会生成散点图矩阵  sactterplotMatrix(矩阵，spread=FALSE,lty.smooth=2,main=" 名字"）
effects包中的effect()函数，你可以用图形展示交互项的结果.
plot(effect(term,mod,xlevels),multiline=TRUE)term即模型要画的项，mod为通过lm()拟合的模型，xlevels是一个列表，指定变量要设定的
常量值，multiline=TRUE选项表示添加相应直线
回归诊断:通过confint()函数的输出来看看多元回归问题。
R基础安装中提供了大量检验回归分析中统计假设的方法。最常见的方法就是对lm()函数返回的对象使用plot()函数，可以生成评价模型拟合情况的四幅图形
     fit <- lm(weight~height,data=women)
     par(mfrow=c(2,2))
     plot(fit)
    图形解读：
    正态性 当预测变量值固定时，因变量成正态分布，则残差值也应该是一个均值为0的正
态分布。正态Q-Q图（Normal Q-Q，右上）是在正态分布对应的值下，标准化残差的概率
图。若满足正态假设，那么图上的点应该落在呈45度角的直线上；若不是如此，那么就
违反了正态性的假设。
   独立性 你无法从这些图中分辨出因变量值是否相互独立，只能从收集的数据中来验证。
上面的例子中，没有任何先验的理由去相信一位女性的体重会影响另外一位女性的体重。
假若你发现数据是从一个家庭抽样得来的，那么可能必须要调整模型独立性的假设。
    线性 若因变量与自变量线性相关，那么残差值与预测（拟合）值就没有任何系统关联。
换句话说，除了白噪声，模型应该包含数据中所有的系统方差。在“残差图与拟合图”
（Residuals vs Fitted，左上）中可以清楚的看到一个曲线关系，这暗示着你可能需要对回
归模型加上一个二次项。
    同方差性 若满足不变方差假设，那么在位置尺度图（Scale-Location Graph，左下）中，
水平线周围的点应该随机分布。该图似乎满足此假设。


qqPlot() 分位数比较图   p199
durbinWatsonTest() 对误差自相关性做Durbin-Watson检验
crPlots() 成分与残差图
ncvTest() 对非恒定的误差方差做得分检验
spreadLevelPlot() 分散水平检验
outlierTest() Bonferroni离群点检验
avPlots() 添加的变量图形
inluencePlot() 回归影响图
scatterplot() 增强的散点图
scatterplotMatrix() 增强的散点图矩阵
vif() 方差膨胀因子


标准方法：
1.正态性检验 ：library(car)
            fit <- lm(Murder~Populaton+Illiteracy+Income+Frost,data=states)
            qqPlot(fit,labels=row.names(states),id.method="identify",simulation=TRUE,main="qq-plot")
绘制学生化残差图的函数   
            residplot <- function(fit,nbreaks=10){
                        z <- rstudent(fit)
                        hist(z,breaks = nbreaks,freq = FALSE,
                               xlab = "studentized residual",
                               main = "distribution of error")
                        rug(jitter(z),col = "brown")
                        curve(dnorm(x,mean = mean(z),sd=sd(z)),
                               add = TRUE,col="blue",lwd=2)
                        lines(density(z)$x,density(z)$y,
                               col="red",lwd=2,lty=2)
                        legend("topright",
                               legend = c("normal curve","kernel density curve"),
                               lty=1:2,col = c("blue","red"),cex=.7)
                               }
              residplot(fit)
2.误差的独立性:  durbinWatsonTest(fit)
3.线性：         crPlots(fit)
4.同方差性：     ncvTest(fit)
                spreadLevelPlot(fit)

线性模型假设的综合验证：
             library(gvlma)
             gvmodel <- gvlma(fit)
             summary(gvmodel)

多重共线性：可用统计量VIF（Variance Inflation Factor，方差膨胀因子）进行检测。VIF的平方根表示变量回归参数的置信区间能膨胀
     为与模型无关的预测变量的程度（因此而得名）。car包中的vif()函数提供VIF值。一般原则下， 跟号下vif >2就表明存在多重共线性问题。
    vif(fit)
    sqrt(vif(fit))>2 # problem?

离群点：outlierTest(fit)
高杠杆值点：高杠杆值的观测点可通过帽子统计量（hat statistic）判断。对于一个给定的数据集，帽子均值为p/n，其中p 是模型估计的参数数
           目（包含截距项），n 是样本量。一般来说，若观测点的帽子值大于帽子均值的2或3倍，即可以认定为高杠杆值点。
           hat.plot <- function(fit){
                        p <- length(coefficients(fit))
                        n <- length(fitted(fit))
                        plot(hatvalues(fit),main="index plot of hat value")
                        abline(h=c(2,3)*p/n,col="red",lty=2)
                        identify(1:n,hatvalues(fit),names(hatvalues(fit)))
                      }
           hat.plot(fit)
强影响点：有两种方法可以检测强影响点：Cook距离，或称D统计量，以及变量添加图（added variableplot）。一般来说，Cook’s D值大于
           4/(nk 1)，则表明它是强影响点，其中n 为样本量大小，k 是预测变量数目。
         cutoff <- 4/(nrow(states)-length(fit$coefficients)-2)
         plot(fit,which=4,cook.levels = cutoff)
         abline(h=cutoff,lty=2,col="red")

         avPlots(fit,ask = FALSE,onepage=TRUE,id.method="identify")
         influencePlot(fit,id.method = "identify",main="influence plot",
              sub="cricle size is proportional to cook's distance")
纵坐标超过+2或小于-2的州可被认为是离群点，水平轴超过0.2或0.3的州有高杠杆值（通常为预测值的组合）。圆圈大小与影响成比例，圆圈很大
        的点可能是对模型参数的估计造成的不成比例影响的强影响点


模型比较    anova()函数同时还对是否应该添加Income和Frost到线性模型中进行了检验。由于检验不显著（p=0.994），因此我们可以得出结论
          ：不需要将这两个变量添加到线性模型中，可以将它们从模型中删除。
           AIC（Akaike Information Criterion，赤池信息准则）也可以用来比较模型，它考虑了模型的统计拟合度以及用来拟合的参数数目。
           AIC值越小的模型要优先选择，
fit1 <- lm(Murder~Population+Illiteracy+Income+Frost,data = states)
fit2 <- lm(Murder~Population+Illiteracy,data = states)
anova(fit2,fit1)
AIC(fit1,fit2)

#逐步回归
library(MASS)
fit1 <- lm(Murder~Population+Illiteracy+Income+Frost,data = states)
stepAIC(fit1,direction = "backward")
#全子集回归
install.packages("leaps")
library(leaps)
leaps <- regsubsets(Murder~Population+Illiteracy+Income+Frost,data = states,nbest=4)
plot(leaps,scale = "adjr2")
subsets(leaps,statistic="cp",main="cp plot for all subsets regression")
abline(1,1,lty=2,col="red")
#深层次分析,交叉验证
library(bootstrap)
shrinkage <- function(fit,k=10) {
  require(bootstrap)
  theta.fit <- function(x,y){lsfit(x,y)}
  theta.predict <- function(fit,x){cbind(1,x)%*%fit$coef}
  x<- fit$model[,2:ncol(fit$model)]
  y <- fit$model[,1]
  results <- crossval(x,y,theta.fit,theta.predict,ngroup = k)
  r2 <-cor(y,fit$fitted.values)^2
  r2cv <- cor(y,results$cv.fit)^2
  cat("original r square = ",r2,"\n")
  cat(k,"fold cross validated r square =",r2cv,"\n")
  cat("change = ",r2-r2cv,"\n")
  }
fit <- lm(Murder~ Population+Illiteracy+Income + Frost,data=states)
shrinkage(fit)
fit2 <- lm(Murder~Population+Illiteracy,data = states)
shrinkage(fit2)

#相对重要性
zstates <- as.data.frame(scale(states))
zfit <- lm(Murder~ Population+Illiteracy+Income + Frost,data=zstates)
coef(zfit)
#计算预测变量的相对权重
relweights <- function(fit,...){
  r <- cor(fit$model)
  nvar <- ncol(r)
  rxx <- r[2:nvar,2:nvar]
  rxy <- r[2:nvar,1]
  svd <- eigen(rxx)
  evec <- svd$vectors
  ev <- svd$values
  delta <- diag(sqrt(ev))
  lambda <- evec %*% delta%*%t(evec)
  lambdasq <- lambda^2
  beta <- solve(lambda) %*% rxy
  rsquare <- colSums(beta^2)
  rawwgt <- lambdasq %*% beta^2
  import <- (rawwgt/rsquare)*100
  lbls <- names(fit$model)[2:nvar]
  rownames(import) <- lbls
  colnames(import) <- "weight"
  barplot(t(import),names.arg = lbls,
          ylab = "% of r square",
          xlab = "predictor variable",
          main = "relative importance of predictor variance",
          sub = paste("r square = ",round(rsquare,digits = 3)),
          ...)
  return(import)
    }
fit <- lm(Murder~ Population+Illiteracy+Income + Frost,data=states)
relweights(fit,col="lightgrey")

































